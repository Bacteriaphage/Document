chapter 1.
  Three important factors for a system: reliability, scalability, maintainability
  Reliablity: 
    fault vs failure: single component/user/etc. can make fault, if that cause whole system down, that's a failure.
    We can deliberately introduce fault to system to make it resilient/fault-tolerant.
    idealy, we better reduce faults in each component, but in reality, we have to deal with them.
    Hardware error: add redundancy or have software to handle faults
    Software error: hard to find, can cause cascading failures, better to carefully think when design, thorough testing, allowing crash and restart
                    monitoring, analyzing system behavior in production. Look for guarantee like sum check, sequence check to make self check.
    Human error: human error is the leading cause of outage comparing to software and hardware. We need to design system in a way that easy for 
                 human to do the right thing instead of the wrong thing, which refer to a well API design, a user-friendly UI etc.
                 Sandbox is important for detacting human error. Thoroughly test at all levels, Quick and easy recovery(rollback)
                 Monitoring, good management practice.
  Scalability:
    Before working on scalability, the first thing is to understand what is current load.
    learning case: Twitter
      In 2012, all twitter users publish 4.6k/s tweets on average, 12k/s tweets at peak. Each user has 75 followers on average, millions followers for celebrities.
      Users make 300k/s read requests.
      When a User open twitter, he/she will read tweets in home timeline, both from normal user and celebrities. To execute a query to join follows/tweets/users will
      space lots of time. A alternative way is to push new tweets to user's own cache, but for celebrities who has millions of followers, this will introduce
      more problems.
      So twitter use hybrid mode which using normal join for celebrities, using cache for normal users.
    Describe performance:
      Think about two things: 1. when load parameters goes up, what happened if resource doesn't change? 2. how much new resource we need to fulfill new load parameters
      A batch processing system more focuses on throughput, online system more focuses on response time. We can decouple those two in some use case likes
      Exchange Trading System. Matching engine itself is a batch process system, and the module to get market data and send information back to clients is 
      a online system.
      Percentile/median is better than mean when describe performance. It tells us how many user request are slower than a number(median).
      The response time are different between what client see and what the system see, it is because a slow culprit will make all later client requests wait. System
      only calculate response time as normal, but client actually feels the slowness. So we have two ways to measure performace a little bit accurate:
        1. monitor performance on client side, 2. Sending request independently, don't wait previous request to be finished.
      To calculate percentiles in a sliding window, add up data in a time window and get the result, or use forward decay, t-digest, HdrHistogram.
    Cope increasing load:
      Use a more powerful machine or employ more small elastic machine? Is the service stateless or stateful? Which part of the system is the bottleneck? How about
      maintainance effort we need for new resource?

chapter 2.
  Data model (relational or document) and query language
  Relational DB vs Document DB:
    If application has lots of one to many data, then Document DB (NoSQL) is a good choice, no join is needed and data are easy to be retrieved.
    If we don't a have a fixed schema, we better to use NoSQL database, which is the schema-on-read pattern. It's like RTTI in C++, we cannot assume schema in databse
    until we are reading it. In contrust, relational databse is schema-on-write, we have to follow certain rules when writing.
    When we need to change schema often, NoSQL is preferred in terms of the slowness when altering table in some relational DB. They probably require some downtime.
    If we access set of data in locality pattern, we can use NoSQL, because to join different tables, access indices will require lots of disk IO. NoSQL can
    provide good locality attribute. However, if the amount of data we query is relatively small comparing to cache or we will modify the size of encoded data, it will
    be expensive to achieve them in NoSQL.
  Nowaday, relational and document DB are more and more complementing each other, relational DB has no schema JSON and NoSQL DB resolve relational reference. This 
  hybrid of two models is good route for databases in the future. 
  Query Language:
    declarative query language (SQL, relational algebra, CSS, MapReduce lang, Cypher node4j) vs imperative language
    MapReduce is used by distributed data storage, but not the essential tool. SQL does not constrain to only run in a single node.
    MongoDB use MapReduce, but also have tools like aggregation pipeline to deal with distributed use cases.
    Graph-like data module use vertices and edge to store data and their relation. Any two vertices can connect with each other and user can traverse forward and 
    backward. The relationship of edges can be different, so a graph can represent different information.
    Semantic web and RDF data model: RDF is a machine readible web which similar to the information on the internet which human can understand. There are lots of
    work to be done like standard proposal, complex, etc. (page 57)
