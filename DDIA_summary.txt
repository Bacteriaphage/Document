chapter 1.
  Three important factors for a system: reliability, scalability, maintainability
  Reliablity: 
    fault vs failure: single component/user/etc. can make fault, if that cause whole system down, that's a failure.
    We can deliberately introduce fault to system to make it resilient/fault-tolerant.
    idealy, we better reduce faults in each component, but in reality, we have to deal with them.
    Hardware error: add redundancy or have software to handle faults
    Software error: hard to find, can cause cascading failures, better to carefully think when design, thorough testing, allowing crash and restart
                    monitoring, analyzing system behavior in production. Look for guarantee like sum check, sequence check to make self check.
    Human error: human error is the leading cause of outage comparing to software and hardware. We need to design system in a way that easy for 
                 human to do the right thing instead of the wrong thing, which refer to a well API design, a user-friendly UI etc.
                 Sandbox is important for detacting human error. Thoroughly test at all levels, Quick and easy recovery(rollback)
                 Monitoring, good management practice.
  Scalability:
    Before working on scalability, the first thing is to understand what is current load.
    learning case: Twitter
      In 2012, all twitter users publish 4.6k/s tweets on average, 12k/s tweets at peak. Each user has 75 followers on average, millions followers for celebrities.
      Users make 300k/s read requests.
      When a User open twitter, he/she will read tweets in home timeline, both from normal user and celebrities. To execute a query to join follows/tweets/users will
      space lots of time. A alternative way is to push new tweets to user's own cache, but for celebrities who has millions of followers, this will introduce
      more problems.
      So twitter use hybrid mode which using normal join for celebrities, using cache for normal users.
    Describe performance:
      Think about two things: 1. when load parameters goes up, what happened if resource doesn't change? 2. how much new resource we need to fulfill new load parameters
      A batch processing system more focuses on throughput, online system more focuses on response time. We can decouple those two in some use case likes
      Exchange Trading System. Matching engine itself is a batch process system, and the module to get market data and send information back to clients is 
      a online system.
      Percentile/median is better than mean when describe performance. It tells us how many user request are slower than a number(median).
      The response time are different between what client see and what the system see, it is because a slow culprit will make all later client requests wait. System
      only calculate response time as normal, but client actually feels the slowness. So we have two ways to measure performace a little bit accurate:
        1. monitor performance on client side, 2. Sending request independently, don't wait previous request to be finished.
      To calculate percentiles in a sliding window, add up data in a time window and get the result, or use forward decay, t-digest, HdrHistogram.
    Cope increasing load:
      Use a more powerful machine or employ more small elastic machine? Is the service stateless or stateful? Which part of the system is the bottleneck? How about
      maintainance effort we need for new resource?

chapter 2.
  Data model (relational or document) and query language
  Relational DB vs Document DB:
    If application has lots of one to many data, then Document DB (NoSQL) is a good choice, no join is needed and data are easy to be retrieved.
    If we don't a have a fixed schema, we better to use NoSQL database, which is the schema-on-read pattern. It's like RTTI in C++, we cannot assume schema in databse
    until we are reading it. In contrust, relational databse is schema-on-write, we have to follow certain rules when writing.
    When we need to change schema often, NoSQL is preferred in terms of the slowness when altering table in some relational DB. They probably require some downtime.
    If we access set of data in locality pattern, we can use NoSQL, because to join different tables, access indices will require lots of disk IO. NoSQL can
    provide good locality attribute. However, if the amount of data we query is relatively small comparing to cache or we will modify the size of encoded data, it will
    be expensive to achieve them in NoSQL.
  Nowaday, relational and document DB are more and more complementing each other, relational DB has no schema JSON and NoSQL DB resolve relational reference. This 
  hybrid of two models is good route for databases in the future. 
  Query Language:
    declarative query language (SQL, relational algebra, CSS, MapReduce lang, Cypher node4j) vs imperative language
    MapReduce is used by distributed data storage, but not the essential tool. SQL does not constrain to only run in a single node.
    MongoDB use MapReduce, but also have tools like aggregation pipeline to deal with distributed use cases.
    Graph-like data module use vertices and edge to store data and their relation. Any two vertices can connect with each other and user can traverse forward and 
    backward. The relationship of edges can be different, so a graph can represent different information.
    Semantic web and RDF data model: RDF is a machine readible web which similar to the information on the internet which human can understand. There are lots of
    work to be done like standard proposal, complex, etc. (page 57)
chapter 3.
  Hash index: build hash index upon different field can boost reading speed, database engine will figure out which index is needed. However, we cannot store all
    index in memory, we group part of indices into segments and write them into disk. In the meantime, data in segment would have duplication, we need to compact
    them.
    The disadvantage of hash index are 1. when index is in disk, the performance is not very good. 2. when query range of data, it will need to scan the whole hash 
    table
  SSTable and LSM-Trees:
    1. the k-v pairs need to be sorted by key in a segment and one key only appear once in a segment file after merging
    2. We only keep a sparse index table (sorted) in memory, each index point to the offset of key within a sorted segment file(SSTable) which is a small block. 
       If the queried key is in between of two sparse indices, we only need to load the small compressed data block in SSTable
    Steps of building SSTable:
      1. write new data into an in-memory sorted balanced tree which we call memtable.
      2. When the size of memtable exceed threshold, we write it into a SSTable and store it on the disk.
      3. To find a record, we check memtable first, then the SSTable in starting from the latest.
      4. Merge can compact SSTable in the background to save space.
      5. To avoid losing memtable when crash, store log for memtable write without order into disk.
    Performance improvement:
      Bloom filters when read
      Size-tiered compaction is for write intensive db, several small SSTable will be compacted into a larger one, this need 2x size of compacted data disk space.
      Leveled compaction will compact L0 SSTable to higher level continuously. There are two parameters 1. max SSTable size, 2. max size of LevelX.
      https://www.youtube.com/watch?v=TyTXOjFMi7k&t=617s&ab_channel=DataStaxDevelopers
      Max size of LevelX is max SSTable size times X power of 10. L0 is a temporary level to store data, compactor will merge data from all SSTables in L0 and merge
      new data with L1 SSTable, write them into a file not exceeding Max SSTable size and store them into L1. If the size of L1 exceed max size of Lv1, promote and
      merge SSTables in Lv1 with Lv2 SSTables until remaining table in Lv1 fit in max size of L1 and so on.
      https://www.youtube.com/watch?v=6yJEwqseMY4&ab_channel=DataStaxDevelopers
      This is good for reading, when writing happenes, it is very IO intensive
    Log-structured Merge-Tree:
      Instead of calling it as a tree, it is more like a filesystem containning SSTable, MemTable, bloom filter and in memory index table.
  B-tree:
    When B tree insert new record and split a node, DB need to seek and write two pages for split and update parent page, which is a vulnerable operation. Because
    when crash happens, index will be corrupted. We use WAL(write-ahead-log) to protect, it's an append only log on disk, updated before the pages of tree get updated.
    we use latch(lightweight locks) to protect concurrency scenario.
    Optimization:
      Instead of overwriting pages and maintaining WAL for crash recovery, we use copy-on-write which doesn't overwrite original pages but create and copy to a new one
      , it's also good for concurrency.
      We can use abbreviating key instead of real one to add more key in to one node which gives us larger branching factor thus fewer levels, it's good for access key
      Leaf node will add reference to it's sibling left and right allowing scanning keys in order without jumping back to paranet pages.
  Comparing B-Tree and LSM-Tree:
    LSM-Tree is faster for write and B-tree is faster for read, since LSM-tree need to check several different data structure and SSTables.
    Advantage of LSM-tree:
      B-tree must write twice once for WAL one for actual pages when inserting.
      Log-structured indexes also rewrite data multiple times due to compaction and merging which we called write amplification.
      However LSM-tree can typically sustain higher write throughput because of low amplification, and sequentially write compact SSTable is faster then overwrite
      several ramdom pages in a tree, especially on a hard disk.
      LSM-tree is compressed better, it takes smaller disk space. B-tree sometimes leave half of page unused after splitting.
    Disadvantage of LSM-tree:
      LSM-tree need make limited disk IO have to wait for an expensive compaction, this cause high latency at higher percentiles.
      When migrate data into a new DB, the initial write take lots of time because of the on going compaction in the background
      If write rate is high and compaction is not configured well, the compaction cannot keep up with the incoming writes, which easily make disk out of space.
      B-tree only have one copy of key in the tree, but LSM-tree has multiple copies of a key in different SSTables. B-tree can offer strong transactional semantics
      because we can just lock on ranges of keys by attach locks to tree.
  Storing values within the index:
    cluster index(storing all rwo data within the index) and heap file (the file which index reference points to) are two opposite way to refer data.
  Multi-column indexes:
    concatenateed index.
  Full-text search and fuzzy indexes:
    helpful when dealing with misspelled word, works with edit distance.
  In-memory database:
    In-memory database is faster not because of not reading from disk, but it don't need to encoding in-memory data structure in a form that can be written to disk.
    It is also good for storedata models that are difficult to implement with disk-based indexes like priority queue and sets.
    In memory database can deal with data which larger than available memory. The so-called anti-caching approach evict the least recently used data from memory to
    disk, similar as how swap works.
  OLAP and OLTP:
    OLAP data warehouse: large amount of data, read intensively, don't write so much.
    Big company always dump data from different OLTP DB into one OLAP DB for analysis purpose.
    OLAP DB has a fact table in both Stars and Snowflakes module as a contral core. It contains all events and each event row has lot of columns for reference
    of different dimensions.
    Comparing to Stars module, Snowflake has sub-core and breaking down dimension table to get highly normallized attribute.
  Column-Oriented Storage:
    We often query only one or two columns, there is no need to read the whole row. We can store each column of a table in one file, which is very good for compression
    as well. The distinct value in one column is normally much smaller than number of rows, so we use bitmap to represent value in each rows. Each distinct value has
    one bitmap, each row has one bit, if a row has this distinct value, the bit is 1 vice versa.
    Then we encode the bit map to several numbers indicate how many consecutive 0 and 1
    This bitmap can even work well for AND and OR operation
    It is also good for single-instruction-multi-data instruction in mordern CPUs.
    It can fit into L1 cache comfortably.
    
    sorted column storage is good for the compression, the encoded data is very small for the sorted column, even encoded data for other columns is the same size
    it's still a very good optimization. Column-oriented storage can use LSM-tree because it doesn't matter whether the in-memory store is column oriented or 
    row oriented, it will compact, merge and sort anyway.
  Aggregation in OLAP:
    We use materialized view(aggregation) to cache multiple aggregation for reading. We can have several two dimensional tables to store data and we can aggregate
    those table again to get aggregation for one dimension.
Chapter 4. Encoding
  Json, XML, CSV
    Benefit and drawback (pg. 114)
    Binary encoding is very important when transport large data. The naive way to encode JSON waste lots of space.
  Thrift and Protocol Buffers:
    Both Thrift and protocol buffer use number to represent key name, and we only need to check number-key map during decoding, save lots of space if key is long.
    In Thrift BinaryProtocol, encoded data is not so much compacted, but in Thrift CompactProtocol and Protocol Buffer, key number and value type are compacted into
    1 byte, all number value have flexible space instead of 64/32 bits. A lead bit is employed to indicate whether there are still incoming bytes for the value, so
    each byte has 7 bits to store part of value, and 1 bit is the indicator.
    Forward/backward compactibility: we can change the key name, but not he key number, old code will ignore unrecognized key number and type/length field will help
    it to skip. All new fields add after the first version must be optional or have a default value.
  Avro - Hadoop encoding method:
    only length and value are concatenated, same varible size number as Thrift compactprotocol and protocol buffer. No field information, no type information. There
    are reader schema and writer schema to store data type and field name. Reader will get writer schema, comparing with reader schema then parse data. writer schema
    is store in 1. beginning of large data file which under the same writer schema; 2. a table referring to a version number, the version number is in small data set;
    3. setup communication process when RPC begin.
    Avro is good for dynamically generate schema but Thrift have to manually assign field number to a field, and manually update field name.
  For Thrift and protocol buffer, they rely on code generation, which is useful when the programming language is statically type language like C, C++ and Java. They
  allow type checking and efficient in-memory structure for known type. This become an unnecessarily obstacle in dynamically typed languages like Javascript, Python.
  Avro is good for them and Avro also provide code generation for C, C++ and Java.
  
  Model of Dataflow
    Via Database: Using database as a media requires forward and backward compatibility. This need to be considered both in encoding/decoding aspect and application
    aspect.
    Via Network (RPC and REST): Microservice architecture makes each service request and respond to other services. They only expose its api to the outside and good
      for restricting on what a client can and cannot do. Each service only maintained by one team, and the team can upgrade service without having to coordinate with
      other teams. old and new version of server/client should be enable to exist at the same time without any encoding/decoding issue.
      SOAP is an XML based protocol, a client can access a remote service using local classes and method call. it is useful in statically typed language. But different
      extensions in different vendors may cause compatibilty problem.
      RestFul is popular in the context of cross-organizational service integration and microservices.
      RPC flaw: RPC request is unpredictable, it may return nothing without exception, it also may doing something on the server side but no respond, in this case,
      another try will cause duplicated operations. The responsd time largely varies. RPC need to copy all values instead of pass by reference/pointer in local.
      RPC call between two endpoint which use different language becauses ugly. Translating from datatype in A language to type in B language is very unreliable.
      Because of the limitation, RPC often is used on requests between services owned by the same org within the same datacenter. It combining with binary encoding
      usually has better performance than JSON over REST.
      But RESTful api is good for experimentation and debugging, it doesn't need any compilation and web browser/curl can easily be the tool to test the protocol.
      For RPC schema evolution, it's reasonable to assume servers will be update first then client, so server need to be backward compatible and client need to be
        forward compatible. How to manage the compatibility properties of RPC depends on what data encoding method it use. Thrift/gRPC(Protocol Buffer)/Avro RPC use
        their own rules to manage compatibility. RESTful JSON API add optional request parameters and add new fields to response objects to maintain compatibility.
        SOAP use XML schema
    Via Asynchronous message passing systems:
      Client deliver message to another process via the middleware instead of direct network connection. Sender only send message, doesn't expect reply. one process
      can be a sender and a reveiver, but those two parts work in different channels. This is why it is call asynchronous. (RabbitMQ, Kafka, ActiveMQ...)
    Distribute actor framework: a programming model for convurrency in a single process(pg.138)
Chapter 5. Replication
  When we need replication server:
    1. keep data goegraphically close to users
    2. allow the system to continue working even if some of it's parts have failed
    3. scale out the number of machines that can serve read queries. 
  Single Leader, multi-leader and leaderless
    systems having Leader: relational DB(Postgresql, mySql, Sql server...), non-relational DB(mongoDB, Espresso, RethinkDB...), message broker(kafka, rebbitMQ...)
    synchronous vs asynchronous replication:
      sync: leader needs to wait for follower's respond before reporting success to user. There is impractical to make all replica sync because any of them fail
            for any reason will make the whole write halt. Usually, one of the replica need to be synchronous, other just asynchronous. If the synchronous replica
            is slow or unavailable, one of the async replica becomes sync. This configuration is somtimes called semi-synchronous
      Often, leader-based replication is configured to be completely asynchronous. This means write is not guaranteed to be durable. Chain replication is a sync
       replication used in Azure storage, provide good performance and do not lose data. The workflow for replication is: Leader->replica->replica->...->tail. A
       naive chain replication only read from tail. It provide high consistancy and reduce the workload for leader for high write throughput. But read throughput
       is low. CRAQ adding dirty/clean flag to data in each replica, new data is dirty in replica until an acknowledge from tail is received, then change dirty
       to clean and overwrite original data(if it's insert not update, no overwrite is needed). User can read from every replica, if users see both clean and dirty
       row, confirm the latest clean data from tail.
    Add new followers:
      1. get snapshot from leader, 2. apply it to the new followers, 3. request all data changes since snapshot was taken in leader, 4. followers use this log to
      catch up with leader.
    Handle node outage:
      Follower failover: catch up using logs, starting from where it failed to the latest leader log.
      leader failover: 1. determine leader fail, 2. choose a new leader, 3. reconfiguring system using the new leader.
        new leader in async replication system might lose unreplicated record. Two leader might exist. The original leader might not actually fail, maybe just slow,
        in this scenario, elect new leader and reconfiguring the system make things worse.
    Replication log:
      Statement based replication: replicate SQL statement, easy but replication must not include indeterministic statement like RAND, not stable order operation etc.
      WAL(write-ahead-log) shipping: LSM and B-tree both have WAL, WAL describes data on a very low level, it contains details of which bytes were changed in which
      disk blocks, so the different version of software will cause issues.
      Logical log replication: human understandable log, like all new values of all columns for insert. key or all values for a deleted row. information of all value
      for updated row and the original key or all values if no key is available.
      Trigger-based replication(pg.161)
    Multi-Leader Replication:
      The most useful case: we have different data center, each data center has a leader, a leader write to it's own replicas and ohter leaders in other datacenters.
      Another case is user has several devices and most of time they are offline, user make change on some of devices and evetually all data need to be sync. 
      The biggest problem, if two clients write the same field with different value to two data center, the data conflict is invulnerable.
      To avoid conflict, we can make all changes for one field only go through one data center, so it acts like a single leader. But it is a problem when the leader
      is down or user move the another location and the data should not write to the original data center any more.
      Convergent conflict:
        If we don't have conflict avoidance, we can 1. give each write a unique ID and the highest ID win, but it will lose data. 2. Give replica ID, the writes
        originated at the higher ID replica always take precedence over writes originated at the lower ID replica, it will lose data as well. 3. Combine all value
        together. 4, preserve all data, let application resolve the conflict.
      Custom conflict resolution can happen on read or on write.
      Automatic conflict resolution: 1. conflict-free replicated datatype, 2. Mergeable persistent data structure. 3. operational transformation.
      https://medium.com/coinmonks/operational-transformations-as-an-algorithm-for-automatic-conflict-resolution-3bf8920ea447
      Topologies: leader needs to update other leaders in a topology pattern. There are three easy patterns: circular, star, all to all.
    Leaderless:
      Client write to all replicas in a datacenter, and also read from all replicas. Because there are multiple clients and considering latency, the writes have no
      order.
      To make sure client write update-to-date record, quorum consistency need to be fulfilled that is: N is number of replicas in a datacenter, W is number of
      replicas who have a successful write, R is number of replicas from which client can read from. DB must have R + W > N configuration to make sure at
      least one replica the client read from has the correct value. To check which is the correct value, we add version information to the rows.
      But quorun consistency has limitation as well, like if two writes happen concurrently, no one can confirm which is the latest version, if write and read
      happen concurrently, we don't know whether we read an old or new value. There are lot of scenaio(pg.181)
      When some replicas fail write, we need make them catch up with the correct data, there are two ways: 1. read repair, if a read from replicas contains stale
      values, use the correct version value to update whose stale value replicas. 2. anti-enthropy process: a background process looks for differences in the data
      between replicas and copies any missing data from one replica to another.
      Sloppy Quorums and hinted handoff:
        If client has connection issue to some designated nodes, but still have other nodes available, client can write to other nodes as a temporary place to save
        write, after connection is fixed, move those new data back to those designated nodes.(hinted handoff). In this case, W is not the normal number of successful
        write replica, so it's call sloppy quorums. It is a weakness for quorum consistency, even W' + R > N, we still cannot make sure clients can read the correct
        version.
    Detecting concurrent write:
      In leaderless or multi-leader system, if multiple client write to one key, concurrent will happen. But how can we detect this and how to make sure all data
      can be somehow saved not dropped like LWW (LWW cannot be applied here because leaderless or multi-leader system has latency or other network issue which
      make the order of write undeterministic). 
      One algo is using one vertor to save value and it's version for one key(pg. 188). One replica cannot do multiple
      writes to one key at the same time, so the version will always increase in server's view. But client will only keep the version it get from server's ack,
      if server see the next push from client has version falling behind then it knows there are some concurrent write happens before this push. Instead of only saving
      current value, this algo saves all values the client write to and get from server into a list.
      To make the server eventual convergency, the server will union all client's list and overwrite old version value.
      To remove items, we need tombstone because simply delete and union will make deleted items reappear.
      To expand this algo to multiple replica in leaderless and multi-leader system, each replica will keep set of vectors and the whole system has version vectors.
Chapter 6. Partitioning
  (1. How does index work with partitioning and partitioning approach; 2. rebalancing; 3. how to route requests to partitions and execute queries)
  Partitioning of Key-Value data:
    1. By key range: sort the key and cut all sorted key into several ranges, store one range to one partition. Good: very good for range queries. Bad: Hot spot are
      very easy to happen. some ranges might have more records than others (skew)
    2. By hashing value. Good: records is placed randomly, if with consistent hashing, they can be evenly balanced among partitions. Bad: hard to do range queries
    3. Cassandra compromise between above to method. Concatenate a key with columns, sort the key and only hash first part of the key, so that it's fast to do range
      queries if first part of the key are the same. It's very good for one-to-many data model.
    All above method cannot avoid skewed workload if one key is hot. In this case, application need to take care of hot key. one solution is to append a small random
      number to the key and split them to different partition. (How multiple keys works? If the key has intensive write, then write to different partition will need
      application read all partitions and resolve version. If the key has intensive read, then it's more like replication.)
  Partitioning and Secondary indexes:
    Instead of using one index to query data, user sometime need other keys to do search, this require the second index key to help make query faster.
    Partitioning secondary indexes by document: each partition keep it's own secondary index for it's own records(color:Red). Querying by a second index needs query 
      all partitions because the same second key might appear in different partitions. It's called scatter and gather which contribute the tail of latency of 
      percentile.
    Partitioning secondary indexes by Term: Comparing to by document approach, it only keeps one second key in one partition, so if delete/insert for this key happens
      in other partitions, this partition needs to be updated asynchrouous as well. The second key also can be sorted and partitioned among partitions.
